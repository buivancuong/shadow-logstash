input {
    file {
        file_completed_action => "log_and_delete"
        file_completed_log_path => "/var/log/logstash/completed.log"
        file_sort_by => "path"
        mode => "read"
        path => "/var/log/uploaded/Microsoft-Sinkhole*.csv"
        sincedb_clean_after => 0.125
        sincedb_path => "/dev/null"
    }
}
filter {
    if [message] =~ /^[,]+\r$/ { drop {} }
    csv {
        skip_empty_rows => true
        columns => [
            "LogTime", "SrcIp", "SrcIpAsn", "geo", "Url", "MaliciousType", "httpAgent", "tor", "SrcPort",
            "pOfGenre", "pOfDetail", "HostName", "DstPort", "MaliciousHostName", "httpReferer", "httpRefererIp",
            "httpRefererAsn", "httpRefererGeo", "DstIp", "DstIpAsn", "DstIpCountryCode2", "naics", "sic",
            "httpRefererNaics", "httpRefererSic", "sector", "sslCipher", "application", "version", "Orgs"
        ]
    }
    if "LogTime" == "timestamp" { drop {} }
    grok { match => { "path" => "/var/log/uploaded/%{GREEDYDATA:FileName}" } }
    ruby { code => "event.to_hash.each { |k, v| event.set(k, '-') if v == nil }" }
    if [SrcIP] == "-" { mutate { replace => { "SrcIP" => "0.0.0.0" } } }
    if [DstIP] == "-" { mutate { replace => { "DstIP" => "0.0.0.0" } } }
    mutate { split => { "Orgs" => "," } }
    prune { whitelist_names => ["@timestamp","@version","message","tags","^[A-Z]"] }
}
output {
    elasticsearch {
        hosts => ["localhost:9200"]
        manage_template => false
        index => "incident_mssinkhole"
        template => "/etc/logstash/template.d/incident_mssinkhole.json"
        http_compression => true
        user => "logstash_user"
        password => "Logst4sh@123"
    }
}
